{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3be9440",
   "metadata": {},
   "source": [
    "# INSTALLING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14472ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parfit\n",
      "  Using cached parfit-0.220.tar.gz (5.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from parfit) (1.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from parfit) (3.7.1)\n",
      "Collecting sklearn (from parfit)\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-plot in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-plot) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-plot) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-plot) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: contractions in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\prince.maponyane\\appdata\\local\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install parfit\n",
    "!pip install scikit-plot\n",
    "!pip install contractions\n",
    "!pip install wordcloud\n",
    "! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf004813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Prince.Maponyane\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import the relevent libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b871e7",
   "metadata": {},
   "source": [
    "# LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609fa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "\n",
    "train_df = pd.read_csv(r'C:\\Users\\Prince.Maponyane\\Downloads\\AI Explore\\6. Classification\\13 Hackathon\\train_set.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\Prince.Maponyane\\Downloads\\AI Explore\\6. Classification\\13 Hackathon\\test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7747f36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check that it loaded\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9904a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check that it loaded\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdcccd",
   "metadata": {},
   "source": [
    "# CREATE DATAFRAME COPIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5e6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create copies of the df's\n",
    "\n",
    "train = train_df\n",
    "test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3b638",
   "metadata": {},
   "source": [
    "# CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db338470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## See the punctuations that will be removed \n",
    "\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0af74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Punctuation \n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([l for l in text if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c32b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        umgaqosiseko wenza amalungiselelo kumaziko axh...\n",
       "1        idha iya kuba nobulumko bokubeka umsebenzi nap...\n",
       "2        the province of kwazulunatal department of tra...\n",
       "3        o netefatša gore o ba file dilo ka moka tše le...\n",
       "4        khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "                               ...                        \n",
       "32995    popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996    modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997    closing date for the submission of completed t...\n",
       "32998    nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999    mafapha a mang le ona a lokela ho etsa ditlale...\n",
       "Name: text, Length: 33000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(remove_punctuation)\n",
    "train['text'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8573645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1       Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2               Tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3       Kube inja nelikati betingevakala kutsi titsini...\n",
       "4                            Winste op buitelandse valuta\n",
       "                              ...                        \n",
       "5677                      You mark your ballot in private\n",
       "5678    Ge o ka kgetha ka bowena go se šomiše Mofani k...\n",
       "5679    E Ka kopo etsa kgetho ya hao ka hloko hobane h...\n",
       "5680    TB ke bokudi ba PMB mme Morero o tla lefella t...\n",
       "5681                  Vakatjhela iwebhusayidi yethu kuwww\n",
       "Name: text, Length: 5682, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'] = test['text'].apply(remove_punctuation)\n",
    "test['text'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79558b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lower Case\n",
    "\n",
    "train['text'] = train['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147af6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39421056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>you mark your ballot in private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>ge o ka kgetha ka bowena go se šomiše mofani k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>e ka kopo etsa kgetho ya hao ka hloko hobane h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>tb ke bokudi ba pmb mme morero o tla lefella t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>vakatjhela iwebhusayidi yethu kuwww</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         1  mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1         2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2         3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3         4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4         5                       winste op buitelandse valuta\n",
       "...     ...                                                ...\n",
       "5677   5678                    you mark your ballot in private\n",
       "5678   5679  ge o ka kgetha ka bowena go se šomiše mofani k...\n",
       "5679   5680  e ka kopo etsa kgetho ya hao ka hloko hobane h...\n",
       "5680   5681  tb ke bokudi ba pmb mme morero o tla lefella t...\n",
       "5681   5682                vakatjhela iwebhusayidi yethu kuwww\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e65804cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [umgaqosiseko, wenza, amalungiselelo, kumaziko...\n",
       "1        [idha, iya, kuba, nobulumko, bokubeka, umseben...\n",
       "2        [the, province, of, kwazulunatal, department, ...\n",
       "3        [o, netefatša, gore, o, ba, file, dilo, ka, mo...\n",
       "4        [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...\n",
       "                               ...                        \n",
       "32995    [popo, ya, dipolateforomo, tse, ke, go, tlisa,...\n",
       "32996    [modise, mosadi, na, o, ntse, o, sa, utlwe, ho...\n",
       "32997    [closing, date, for, the, submission, of, comp...\n",
       "32998    [nawuphina, umntu, ofunyenwe, enetyala, phants...\n",
       "32999    [mafapha, a, mang, le, ona, a, lokela, ho, ets...\n",
       "Name: tokens, Length: 33000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To improve efficiency - tokenize\n",
    "\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "train['tokens'] = train['text'].apply(tokeniser.tokenize)\n",
    "train['tokens'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11274442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [mmasepala, fa, maemo, a, a, kgethegileng, a, ...\n",
       "1       [uzakwaziswa, ngokufaneleko, nakungafuneka, em...\n",
       "2       [tshivhumbeo, tshi, fana, na, ngano, dza, vhathu]\n",
       "3       [kube, inja, nelikati, betingevakala, kutsi, t...\n",
       "4                       [winste, op, buitelandse, valuta]\n",
       "                              ...                        \n",
       "5677               [you, mark, your, ballot, in, private]\n",
       "5678    [ge, o, ka, kgetha, ka, bowena, go, se, šomiše...\n",
       "5679    [e, ka, kopo, etsa, kgetho, ya, hao, ka, hloko...\n",
       "5680    [tb, ke, bokudi, ba, pmb, mme, morero, o, tla,...\n",
       "5681             [vakatjhela, iwebhusayidi, yethu, kuwww]\n",
       "Name: tokens, Length: 5682, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "test['tokens'] = test['text'].apply(tokeniser.tokenize)\n",
    "test['tokens'].iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bde44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Prince.Maponyane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Prince.Maponyane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lang_id                                               text  \\\n",
      "0         xho  umgaqosiseko wenza amalungiselelo kumaziko axh...   \n",
      "1         xho  idha iya kuba nobulumko bokubeka umsebenzi nap...   \n",
      "2         eng  the province of kwazulunatal department of tra...   \n",
      "3         nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
      "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
      "...       ...                                                ...   \n",
      "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...   \n",
      "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...   \n",
      "32997     eng  closing date for the submission of completed t...   \n",
      "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...   \n",
      "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...   \n",
      "\n",
      "                                                  tokens  \\\n",
      "0      [umgaqosiseko, wenza, amalungiselelo, kumaziko...   \n",
      "1      [idha, iya, kuba, nobulumko, bokubeka, umseben...   \n",
      "2      [the, province, of, kwazulunatal, department, ...   \n",
      "3      [o, netefatša, gore, o, ba, file, dilo, ka, mo...   \n",
      "4      [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...   \n",
      "...                                                  ...   \n",
      "32995  [popo, ya, dipolateforomo, tse, ke, go, tlisa,...   \n",
      "32996  [modise, mosadi, na, o, ntse, o, sa, utlwe, ho...   \n",
      "32997  [closing, date, for, the, submission, of, comp...   \n",
      "32998  [nawuphina, umntu, ofunyenwe, enetyala, phants...   \n",
      "32999  [mafapha, a, mang, le, ona, a, lokela, ho, ets...   \n",
      "\n",
      "                                         lemmatized_text  \n",
      "0      umgaqosiseko wenza amalungiselelo kumaziko axh...  \n",
      "1      idha iya kuba nobulumko bokubeka umsebenzi nap...  \n",
      "2      the province of kwazulunatal department of tra...  \n",
      "3      o netefatša gore o ba file dilo ka moka tše le...  \n",
      "4      khomishini ya ndinganyiso ya mbeu yo ewa maana...  \n",
      "...                                                  ...  \n",
      "32995  popo ya dipolateforomo tse ke go tlisa boetele...  \n",
      "32996  modise mosadi na o ntse o sa utlwe hore thaban...  \n",
      "32997  closing date for the submission of completed t...  \n",
      "32998  nawuphina umntu ofunyenwe enetyala phantsi kwa...  \n",
      "32999  mafapha a mang le ona a lokela ho etsa ditlale...  \n",
      "\n",
      "[33000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Lemmatize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_sentence(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text\n",
    "\n",
    "# Apply lemmatization to train and test DataFrames\n",
    "\n",
    "train['lemmatized_text'] = train['text'].apply(lemmatize_sentence)\n",
    "\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39bf98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index                                               text  \\\n",
      "0         1  mmasepala fa maemo a a kgethegileng a letlelel...   \n",
      "1         2  uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
      "2         3          tshivhumbeo tshi fana na ngano dza vhathu   \n",
      "3         4  kube inja nelikati betingevakala kutsi titsini...   \n",
      "4         5                       winste op buitelandse valuta   \n",
      "...     ...                                                ...   \n",
      "5677   5678                    you mark your ballot in private   \n",
      "5678   5679  ge o ka kgetha ka bowena go se šomiše mofani k...   \n",
      "5679   5680  e ka kopo etsa kgetho ya hao ka hloko hobane h...   \n",
      "5680   5681  tb ke bokudi ba pmb mme morero o tla lefella t...   \n",
      "5681   5682                vakatjhela iwebhusayidi yethu kuwww   \n",
      "\n",
      "                                                 tokens  \\\n",
      "0     [mmasepala, fa, maemo, a, a, kgethegileng, a, ...   \n",
      "1     [uzakwaziswa, ngokufaneleko, nakungafuneka, em...   \n",
      "2     [tshivhumbeo, tshi, fana, na, ngano, dza, vhathu]   \n",
      "3     [kube, inja, nelikati, betingevakala, kutsi, t...   \n",
      "4                     [winste, op, buitelandse, valuta]   \n",
      "...                                                 ...   \n",
      "5677             [you, mark, your, ballot, in, private]   \n",
      "5678  [ge, o, ka, kgetha, ka, bowena, go, se, šomiše...   \n",
      "5679  [e, ka, kopo, etsa, kgetho, ya, hao, ka, hloko...   \n",
      "5680  [tb, ke, bokudi, ba, pmb, mme, morero, o, tla,...   \n",
      "5681           [vakatjhela, iwebhusayidi, yethu, kuwww]   \n",
      "\n",
      "                                        lemmatized_text  \n",
      "0     mmasepala fa maemo a a kgethegileng a letlelel...  \n",
      "1     uzakwaziswa ngokufaneleko nakungafuneka eminye...  \n",
      "2             tshivhumbeo tshi fana na ngano dza vhathu  \n",
      "3     kube inja nelikati betingevakala kutsi titsini...  \n",
      "4                          winste op buitelandse valuta  \n",
      "...                                                 ...  \n",
      "5677                    you mark your ballot in private  \n",
      "5678  ge o ka kgetha ka bowena go se šomiše mofani k...  \n",
      "5679  e ka kopo etsa kgetho ya hao ka hloko hobane h...  \n",
      "5680  tb ke bokudi ba pmb mme morero o tla lefella t...  \n",
      "5681                vakatjhela iwebhusayidi yethu kuwww  \n",
      "\n",
      "[5682 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "test['lemmatized_text'] = test['text'].apply(lemmatize_sentence)\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8058b50",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b99ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning X,y\n",
    "\n",
    "X = train['text']\n",
    "y = train['lang_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0eeeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef769b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initializing the TF-IDF vectorizer\n",
    "\n",
    "def preprocess_data(train, test):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "## Fitting the vectorizer on the training data\n",
    "    \n",
    "    vectorizer.fit(train['text'])\n",
    "\n",
    "# Transforming the training and test data using the fitted vectorizer\n",
    "    \n",
    "    train_features = vectorizer.transform(train['text'])\n",
    "    test_features = vectorizer.transform(test['text'])\n",
    "\n",
    "    return train_features, test_features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf248f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, vectorizer = preprocess_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1e83126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.9943976987335509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prince.Maponyane\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression Model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "lr_f1 = f1_score(y_test, lr_preds, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06ba9ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 Score: 0.9620927040666665\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbours\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn_model.predict(X_test)\n",
    "\n",
    "knn_f1 = f1_score(y_test, knn_preds, average='weighted')\n",
    "\n",
    "print(\"KNN F1 Score:\", knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9a0dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 Score: 0.9942548884498323\n"
     ]
    }
   ],
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm.predict(X_test)\n",
    "svm_f1 = f1_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "print(\"SVM F1 Score:\", svm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc982adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.9984848537376715\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "nb_predictions = nb.predict(X_test)\n",
    "nb_f1 = f1_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37654761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1741321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "320fdc97",
   "metadata": {},
   "source": [
    "## Generate Predictions\n",
    "\n",
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c4aec",
   "metadata": {},
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "\n",
    "submission_df = pd.DataFrame({'index': test['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410eb795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068684ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
